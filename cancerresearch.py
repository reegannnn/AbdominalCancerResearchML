# -*- coding: utf-8 -*-
"""CancerResearch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_K5h-gw6Xp1xLB0LLWzJfsjqik9bi696
"""

import pandas as pd

# Load the dataset
data = pd.read_csv("app_data.csv")
data.head()

# Define the threshold for missing values
threshold = 0.6
data_filtered = data.loc[:, data.isnull().mean() < threshold]

missing_data_summary = data_filtered.isnull().mean() * 100
print(missing_data_summary[missing_data_summary > 0].sort_values(ascending=False))

for column in data_filtered.columns:
    if data_filtered[column].dtype == "object":  # Categorical column
        data_filtered[column].fillna(data_filtered[column].mode()[0], inplace=True)
    else:  # Numeric column
        data_filtered[column].fillna(data_filtered[column].median(), inplace=True)

print("Missing values after filling:", data_filtered.isnull().sum().sum())

data_encoded = pd.get_dummies(data_filtered, drop_first=True)

from sklearn.model_selection import train_test_split

# Define features (X) and target (y)
X = data_encoded.drop("Diagnosis", axis=1)
y = data_encoded["Diagnosis"]

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(data_encoded.columns)

# Ensure "Diagnosis" is isolated before encoding other columns
X = data_filtered.drop("Diagnosis", axis=1)
y = data_filtered["Diagnosis"]

# One-hot encode features only (excluding target)
X_encoded = pd.get_dummies(X, drop_first=True)

# Continue with the split
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

# Starting with Random Forest for its robustness and easy interpretation

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Initialize the model
model = RandomForestClassifier(random_state=42)

# Train the model
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Detailed classification report
print(classification_report(y_test, y_pred))

# Fine-tuning steps
# Hyperparameter Tuning with GridSearchCV

from sklearn.model_selection import GridSearchCV

# Define the parameter grid
param_grid = {
    'n_estimators': [100, 200, 300],             # Number of trees
    'max_depth': [None, 10, 20, 30],            # Maximum depth of the tree
    'min_samples_split': [2, 5, 10],            # Minimum number of samples to split a node
    'min_samples_leaf': [1, 2, 4],              # Minimum number of samples at a leaf node
    'bootstrap': [True, False]                  # Method of sampling
}


# Initialize the Random Forest classifier
rf = RandomForestClassifier(random_state=42)

# Initialize GridSearchCV
grid_search = GridSearchCV(
    estimator=rf,
    param_grid=param_grid,
    cv=5,                        # 5-fold cross-validation
    n_jobs=-1,                   # Use all available cores
    verbose=2,
    scoring='f1_macro'           # You can choose other metrics like 'accuracy'
)


# Fit GridSearchCV to the training data
grid_search.fit(X_train, y_train)


# Best parameters found
print("Best Parameters:", grid_search.best_params_)

# Best score achieved during cross-validation
print("Best F1 Score:", grid_search.best_score_)


# Extract the best estimator
best_rf = grid_search.best_estimator_

# Train the best model on the full training data
best_rf.fit(X_train, y_train)

# Feature Importance Analysis - Understanding which features contribute most to the model's predictions can help in feature selection and engineering.

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Get feature importances from the best model
importances = best_rf.feature_importances_
feature_names = X_train.columns

# Create a DataFrame for visualization
feature_importances = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances
})

# Sort the DataFrame by importance
feature_importances = feature_importances.sort_values(by='Importance', ascending=False)

# Plot the top 10 features
plt.figure(figsize=(12,8))
sns.barplot(x='Importance', y='Feature', data=feature_importances.head(10))
plt.title('Top 10 Feature Importances')
plt.tight_layout()
plt.show()

# Cross-Validation - Ensure that your model's performance is consistent across different subsets of the data

from sklearn.model_selection import cross_val_score

# Perform cross-validation with the best model
cv_scores = cross_val_score(best_rf, X_train, y_train, cv=5, scoring='f1_macro')

print("Cross-Validation F1 Scores:", cv_scores)
print("Mean CV F1 Score:", cv_scores.mean())
print("Standard Deviation:", cv_scores.std())

"""Exploring other **models**"""

# Support Vector Machine (SVM)

from sklearn.svm import SVC

# Initialize SVM with probability estimates
svm = SVC(probability=True, random_state=42)

# Define parameter grid for SVM
param_grid_svm = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf'],
    'gamma': ['scale', 'auto']
}

# Initialize GridSearchCV for SVM
grid_search_svm = GridSearchCV(
    estimator=svm,
    param_grid=param_grid_svm,
    cv=5,
    n_jobs=-1,
    verbose=2,
    scoring='f1_macro'
)

# Fit GridSearchCV to the training data
grid_search_svm.fit(X_train, y_train)

# Best parameters and score
print("Best SVM Parameters:", grid_search_svm.best_params_)
print("Best SVM F1 Score:", grid_search_svm.best_score_)

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Predict on the test set
y_pred_best = best_rf.predict(X_test)

# Calculate accuracy
accuracy_best = accuracy_score(y_test, y_pred_best)
print("Final Model Accuracy on Test Set:", accuracy_best)

# Detailed classification report
print("Classification Report:\n", classification_report(y_test, y_pred_best))

# Confusion Matrix
import seaborn as sns

conf_matrix = confusion_matrix(y_test, y_pred_best)
plt.figure(figsize=(8,6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=['No Appendicitis', 'Appendicitis'],
            yticklabels=['No Appendicitis', 'Appendicitis'])
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.title('Confusion Matrix')
plt.show()



"""# Deploying the models"""

import joblib

# Save the trained model
joblib.dump(best_rf, 'diagnostic_model.pkl')

pip install fastapi uvicorn joblib

# app.py
from fastapi import FastAPI
import joblib
import pandas as pd
from pydantic import BaseModel

# Load the trained model
model = joblib.load("diagnostic_model.pkl")

# Initialize the FastAPI app
app = FastAPI()

# Define the input data model for validation
class DiagnosticData(BaseModel):
    feature1: float
    feature2: float
    feature3: float
    # Add more fields based on your dataset features

# Define the endpoint for predictions
@app.post("/predict")
async def predict(data: DiagnosticData):
    # Convert incoming data to a DataFrame
    input_df = pd.DataFrame([data.dict()])
    # Make predictions
    prediction = model.predict(input_df)
    # Return the result
    return {"diagnosis": prediction[0]}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

